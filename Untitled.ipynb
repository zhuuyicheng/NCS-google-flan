{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b60bc2f5-e60d-408b-bf3b-1ed70ed09d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt =\"A step by step recipe to make bolognese pasta:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e036c230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: transformers in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (4.38.2)\n",
      "Requirement already satisfied: datasets in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: rouge-score in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: nltk in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (3.8.1)\n",
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting py7zr\n",
      "  Downloading py7zr-0.21.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from pytesseract) (23.1)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from pytesseract) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from datasets) (15.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: xxhash in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: absl-py in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from rouge-score) (2.1.0)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard)\n",
      "  Downloading grpcio-1.62.1-cp310-cp310-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard)\n",
      "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard)\n",
      "  Downloading protobuf-5.26.0-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from tensorboard) (68.2.2)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard)\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting texttable (from py7zr)\n",
      "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting pycryptodomex>=3.16.0 (from py7zr)\n",
      "  Downloading pycryptodomex-3.20.0-cp35-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting pyzstd>=0.15.9 (from py7zr)\n",
      "  Downloading pyzstd-0.15.9-cp310-cp310-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting pyppmd<1.2.0,>=1.1.0 (from py7zr)\n",
      "  Downloading pyppmd-1.1.0-cp310-cp310-win_amd64.whl.metadata (5.8 kB)\n",
      "Collecting pybcj<1.1.0,>=1.0.0 (from py7zr)\n",
      "  Downloading pybcj-1.0.2-cp310-cp310-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting multivolumefile>=0.2.3 (from py7zr)\n",
      "  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting inflate64<1.1.0,>=1.0.0 (from py7zr)\n",
      "  Downloading inflate64-1.0.0-cp310-cp310-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting brotli>=1.1.0 (from py7zr)\n",
      "  Downloading Brotli-1.1.0-cp310-cp310-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: psutil in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from py7zr) (5.9.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\anaconda3\\envs\\googleflan\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.2/5.5 MB 5.3 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.5/5.5 MB 5.6 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.7/5.5 MB 6.4 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.2/5.5 MB 7.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.5/5.5 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.9/5.5 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.2/5.5 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 2.7/5.5 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.3/5.5 MB 8.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 3.7/5.5 MB 8.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.2/5.5 MB 8.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.5/5.5 MB 8.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.9/5.5 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.4/5.5 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 8.2 MB/s eta 0:00:00\n",
      "Downloading py7zr-0.21.0-py3-none-any.whl (67 kB)\n",
      "   ---------------------------------------- 0.0/67.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 67.6/67.6 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading Brotli-1.1.0-cp310-cp310-win_amd64.whl (357 kB)\n",
      "   ---------------------------------------- 0.0/357.3 kB ? eta -:--:--\n",
      "   --------------------------------------  348.2/357.3 kB 10.9 MB/s eta 0:00:01\n",
      "   --------------------------------------- 357.3/357.3 kB 11.2 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.62.1-cp310-cp310-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/3.8 MB 9.9 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.7/3.8 MB 7.5 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 1.2/3.8 MB 8.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.4/3.8 MB 8.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.7/3.8 MB 7.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.0/3.8 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.3/3.8 MB 7.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.6/3.8 MB 7.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 3.1/3.8 MB 7.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.5/3.8 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 7.6 MB/s eta 0:00:00\n",
      "Downloading inflate64-1.0.0-cp310-cp310-win_amd64.whl (35 kB)\n",
      "Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "   ---------------------------------------- 0.0/105.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 105.4/105.4 kB ? eta 0:00:00\n",
      "Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
      "Downloading protobuf-5.26.0-cp310-abi3-win_amd64.whl (420 kB)\n",
      "   ---------------------------------------- 0.0/420.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 420.9/420.9 kB 13.2 MB/s eta 0:00:00\n",
      "Downloading pybcj-1.0.2-cp310-cp310-win_amd64.whl (24 kB)\n",
      "Downloading pycryptodomex-3.20.0-cp35-abi3-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.4/1.8 MB 8.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.9/1.8 MB 9.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.3/1.8 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.6/1.8 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 8.0 MB/s eta 0:00:00\n",
      "Downloading pyppmd-1.1.0-cp310-cp310-win_amd64.whl (46 kB)\n",
      "   ---------------------------------------- 0.0/46.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.1/46.1 kB ? eta 0:00:00\n",
      "Downloading pyzstd-0.15.9-cp310-cp310-win_amd64.whl (245 kB)\n",
      "   ---------------------------------------- 0.0/245.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 245.3/245.3 kB 15.7 MB/s eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "   ---------------------------------------- 0.0/226.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 226.7/226.7 kB 7.0 MB/s eta 0:00:00\n",
      "Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: texttable, brotli, werkzeug, tensorboard-data-server, pyzstd, pytesseract, pyppmd, pycryptodomex, pybcj, protobuf, multivolumefile, markdown, inflate64, grpcio, tensorboard, py7zr\n",
      "  Attempting uninstall: brotli\n",
      "    Found existing installation: Brotli 1.0.9\n",
      "    Uninstalling Brotli-1.0.9:\n",
      "      Successfully uninstalled Brotli-1.0.9\n",
      "Successfully installed brotli-1.1.0 grpcio-1.62.1 inflate64-1.0.0 markdown-3.6 multivolumefile-0.2.3 protobuf-5.26.0 py7zr-0.21.0 pybcj-1.0.2 pycryptodomex-3.20.0 pyppmd-1.1.0 pytesseract-0.3.10 pyzstd-0.15.9 tensorboard-2.16.2 tensorboard-data-server-0.7.2 texttable-1.7.0 werkzeug-3.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'sudo' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract transformers datasets rouge-score nltk tensorboard py7zr --upgrade\n",
    "# install git-fls for pushing model and logs to the hugging face hub\n",
    "!sudo apt-get install git-lfs --yes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b06e7b82-3c90-4933-bff5-2736238b857a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import T5Tokenizer, DataCollatorForSeq2Seq\n",
    "from transformers import T5ForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "\n",
    "# Load the tokenizer, model, and data collator\n",
    "MODEL_NAME = \"google/flan-t5-large\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48b7574f-5573-4e5c-b48a-c46b9450f3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This computer uses CUDA\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "is_cuda=torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    print(\"This computer uses CUDA\")\n",
    "else:  \n",
    "    print(\"This computer uses CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4418bc",
   "metadata": {},
   "source": [
    "Trying to prepare our own dataset for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fcc7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_id=\"google/flan-t5-base\"\n",
    "\n",
    "# Load tokenizer of FLAN-t5-base\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5664c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv('Incident Description Dataset - LLM data.csv')\n",
    "# print(df.head())\n",
    "dataset = Dataset.from_pandas(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9bf1ac",
   "metadata": {},
   "source": [
    "The following is from the original tutorial, using the yahoo answers QA dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb0853e0-8648-4104-99d0-7b04e3f9ca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire the training data from Hugging Face\n",
    "DATA_NAME = \"yahoo_answers_qa\"\n",
    "yahoo_answers_qa = load_dataset(DATA_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a937b579",
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_answers_qa = yahoo_answers_qa[\"train\"].train_test_split(test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3368d35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'question', 'answer', 'nbestanswers', 'main_category'],\n",
       "        num_rows: 61153\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'question', 'answer', 'nbestanswers', 'main_category'],\n",
       "        num_rows: 26209\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the length of the data and its structure\n",
    "yahoo_answers_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3e54c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We prefix our tasks with \"answer the question\"\n",
    "prefix = \"Please answer this question: \"\n",
    "\n",
    "# Define the preprocessing function\n",
    "\n",
    "def preprocess_function(examples):\n",
    "   \"\"\"Add prefix to the sentences, tokenize the text, and set the labels\"\"\"\n",
    "   # The \"inputs\" are the tokenized answer:\n",
    "   inputs = [prefix + doc for doc in examples[\"question\"]]\n",
    "   model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n",
    "  \n",
    "   # The \"labels\" are the tokenized outputs:\n",
    "   labels = tokenizer(text_target=examples[\"answer\"], \n",
    "                      max_length=512,         \n",
    "                      truncation=True)\n",
    "\n",
    "   model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "   return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5ffb08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  20%|█▉        | 12000/61153 [00:03<00:13, 3589.76 examples/s]c:\\anaconda3\\envs\\googleflan\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:309: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 61153/61153 [00:17<00:00, 3464.11 examples/s]\n",
      "Map: 100%|██████████| 26209/26209 [00:07<00:00, 3587.21 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Map the preprocessing function across our dataset\n",
    "tokenized_dataset = yahoo_answers_qa.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb0be15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"punkt\", quiet=True)\n",
    "metric = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c345bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "   preds, labels = eval_preds\n",
    "\n",
    "   # decode preds and labels\n",
    "   labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "   decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "   decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "   # rougeLSum expects newline after each sentence\n",
    "   decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "   decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "   result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "  \n",
    "   return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9819140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Parameters\n",
    "L_RATE = 3e-4\n",
    "BATCH_SIZE = 8\n",
    "PER_DEVICE_EVAL_BATCH = 4\n",
    "WEIGHT_DECAY = 0.01\n",
    "SAVE_TOTAL_LIM = 3\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "small_train_dataset = tokenized_dataset[\"train\"].select(range(100))  # adjust the range as needed\n",
    "small_eval_dataset = tokenized_dataset[\"test\"].select(range(100))  # adjust the range as needed\n",
    "\n",
    "# Set up training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "   output_dir=\"./results\",\n",
    "   evaluation_strategy=\"epoch\",\n",
    "   learning_rate=L_RATE,\n",
    "   per_device_train_batch_size=BATCH_SIZE,\n",
    "   per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH,\n",
    "   weight_decay=WEIGHT_DECAY,\n",
    "   save_total_limit=SAVE_TOTAL_LIM,\n",
    "   num_train_epochs=NUM_EPOCHS,\n",
    "   predict_with_generate=True,\n",
    "   push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e9cde4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\googleflan\\lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=small_train_dataset,\n",
    "   eval_dataset=small_eval_dataset,\n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator,\n",
    "   compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6124b14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:12<00:00,  1.31it/s]c:\\anaconda3\\envs\\googleflan\\lib\\site-packages\\transformers\\generation\\utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "                                               \n",
      "100%|██████████| 13/13 [00:34<00:00,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.248453378677368, 'eval_rouge1': 0.16996827981451143, 'eval_rouge2': 0.02853226218638956, 'eval_rougeL': 0.13255414124120596, 'eval_rougeLsum': 0.14990923221372135, 'eval_runtime': 21.4024, 'eval_samples_per_second': 4.672, 'eval_steps_per_second': 1.168, 'epoch': 1.0}\n",
      "{'train_runtime': 34.2888, 'train_samples_per_second': 2.916, 'train_steps_per_second': 0.379, 'train_loss': 3.576446533203125, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=13, training_loss=3.576446533203125, metrics={'train_runtime': 34.2888, 'train_samples_per_second': 2.916, 'train_steps_per_second': 0.379, 'train_loss': 3.576446533203125, 'epoch': 1.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "googleflan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
